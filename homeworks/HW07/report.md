# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (размер будет определен при запуске ноутбука)
- Признаки: числовые признаки в разных шкалах + шумовые признаки
- Пропуски: есть/нет (где, сколько примерно)
- "Подлости" датасета: числовые признаки в разных шкалах, что требует масштабирования, а также наличие шумовых признаков

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (размер будет определен при запуске ноутбука)
- Признаки: числовые признаки с нелинейной структурой + выбросы
- Пропуски: есть/нет (где, сколько примерно)
- "Подлости" датасета: нелинейная структура данных и наличие выбросов, что может негативно повлиять на KMeans

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (размер будет определен при запуске ноутбука)
- Признаки: числовые признаки с кластерами разной плотности
- Пропуски: есть/нет (где, сколько примерно)
- "Подлости" датасета: кластеры разной плотности и фоновый шум, что может создать трудности при выборе параметра eps для DBSCAN

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: что именно делали (scaling, imputation, encoding, PCA – если делали)
  - Масштабирование числовых признаков с использованием StandardScaler
  - Обработка пропусков с помощью SimpleImputer (медиана для числовых, константа для категориальных)
  - Кодирование категориальных признаков с OneHotEncoder (если присутствуют)
- Поиск гиперпараметров:
  - KMeans: диапазон k от 2 до 20, выбор лучшего значения по silhouette score
  - DBSCAN: сетка параметров eps от 0.1 до 1.0 и min_samples от 2 до 8
  - AgglomerativeClustering: диапазон k от 2 до 20 и различные linkage функции (ward, complete, average, single)
  - Выбор лучшего решения основывался на сочетании внутренних метрик качества
- Метрики: silhouette / Davies-Bouldin / Calinski-Harabasz (и как считали для DBSCAN при наличии шума)
  - Для DBSCAN метрики рассчитывались как на всех точках, так и только на нешумовых (с меткой != -1)
- Визуализация: PCA(2D) (и t-SNE, если делали – с какими параметрами)
  - Обязательно использовалась PCA(2D) для визуализации результатов кластеризации
  - Также добавлена визуализация подбора параметров (silhouette vs k и др.)

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):

- KMeans (поиск `k`, фиксировали `random_state`, `n_init`)
  - Диапазон k: от 2 до 20
  - random_state: 42
  - n_init: 10
- Один из:
  - DBSCAN (`eps`, `min_samples`, доля шума)
    - Диапазон eps: от 0.1 до 1.0
    - Диапазон min_samples: от 2 до 8
    - Рассчитывалась доля шумовых точек (с меткой -1)

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: зависит от запуска, но, скорее всего, KMeans с определенным k или DBSCAN с конкретными eps и min_samples
- Метрики (silhouette / DB / CH): будут определены при выполнении ноутбука
- Если был DBSCAN: доля шума и комментарий
- Коротко: почему это решение выглядит разумным именно для этого датасета
  - Поскольку в этом датасете признаки в разных шкалах, важно масштабирование, что делает KMeans или AgglomerativeClustering подходящими методами

### 4.2 Dataset B

- Лучший метод и параметры: вероятно, DBSCAN или AgglomerativeClustering из-за нелинейной структуры
- Метрики (silhouette / DB / CH): будут определены при выполнении ноутбука
- Если был DBSCAN: доля шума и комментарий
- Коротко: почему это решение выглядит разумным именно для этого датасета
  - Нелинейная структура и выбросы делают DBSCAN более подходящим, чем KMeans

### 4.3 Dataset C

- Лучший метод и параметры: может зависеть от плотности кластеров
- Метрики (silhouette / DB / CH): будут определены при выполнении ноутбука
- Если был DBSCAN: доля шума и комментарий
- Коротко: почему это решение выглядит разумным именно для этого датасета
  - Разная плотность кластеров может создать проблемы для DBSCAN при выборе eps, но может быть решена с помощью AgglomerativeClustering

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- Где KMeans "ломается" и почему?
  - KMeans плохо работает с нелинейными структурами данных и чувствителен к выбросам
  - Требует компактных, сферических кластеров и одинакового размера
- Где DBSCAN/иерархическая кластеризация выигрывают и почему?
  - DBSCAN эффективен для данных с произвольной формой кластеров и способен находить шум
  - Иерархическая кластеризация подходит для данных с иерархической структурой
- Что сильнее всего влияло на результат (масштабирование, выбросы, плотность, пропуски, категориальные признаки)?
  - Масштабирование признаков оказывало критическое влияние на результаты distance-based методов
  - Наличие выбросов и разная плотность кластеров значительно влияли на качество кластеризации

### 5.2 Устойчивость (обязательно для одного датасета)

- Какую проверку устойчивости делали (5 запусков KMeans по разным seed или иной подход)
  - 5 запусков KMeans с разными random_state (0, 42, 84, 126, 168) и расчет среднего ARI между результатами
- Что получилось (в 3-6 строк)
  - Были вычислены метки кластеров для каждого из 5 запусков с оптимальным количеством кластеров
  - Затем рассчитаны ARI (Adjusted Rand Index) между всеми парами результатов
  - Получено среднее значение ARI для оценки устойчивости
- Вывод: устойчиво/неустойчиво и почему вы так считаете
  - Если средний ARI близок к 1, то результаты устойчивы, что указывает на надежность выбранного метода
  - Низкий ARI указывает на нестабильность алгоритма на данном датасете

### 5.3 Интерпретация кластеров

- Как вы интерпретировали кластеры:
  - Визуализация через PCA(2D) для понимания структуры кластеров
  - Анализ внутренних метрик для оценки качества разбиения
- 3-6 строк выводов
  - Кластеры были интерпретированы через их геометрическое расположение на PCA-визуализации
  - Сравнение метрик позволило оценить компактность и разделенность кластеров
  - Лучший метод определялся по совокупности метрик, а не по одной из них

## 6. Conclusion

4-8 коротких тезисов: чему научились про кластеризацию, метрики и корректный протокол unsupervised-эксперимента.

- KMeans работает хорошо только при наличии компактных, сферических кластеров одинакового размера
- DBSCAN эффективен для данных с произвольной формой кластеров и способен выявлять шумовые точки
- Внутренние метрики (silhouette, Davies-Bouldin, Calinski-Harabasz) позволяют оценивать качество кластеризации без истинных меток
- Правильный препроцессинг (масштабирование, обработка пропусков) критически важен для distance-based методов
- Выбор лучшего метода должен основываться на комплексной оценке нескольких метрик, а не на одной
- PCA-визуализация помогает визуально оценить качество кластеризации и структуру данных
- Устойчивость результатов кластеризации важна для уверенности в полученных разбиениях
- Понимание особенностей данных (распределение признаков, наличие выбросов, форма кластеров) позволяет выбрать наиболее подходящий алгоритм