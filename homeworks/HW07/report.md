# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000, 9) - 12000 строк, 9 столбцов
- Признаки: 8 числовых признаков (f01-f08) в разных шкалах, разные стандартные отклонения
- Пропуски: нет пропусков
- "Подлости" датасета: числовые признаки в разных шкалах, что требует масштабирования, а также наличие шумовых признаков

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000, 4) - 8000 строк, 4 столбца
- Признаки: 3 числовых признака (x1, x2, z_noise), нелинейная структура
- Пропуски: нет пропусков
- "Подлости" датасета: нелинейная структура данных и наличие выбросов, что может негативно повлиять на KMeans

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (15000, 5) - 15000 строк, 5 столбцов
- Признаки: 4 числовых признака (x1, x2, f_corr, f_noise), кластеры разной плотности
- Пропуски: нет пропусков
- "Подлости" датасета: кластеры разной плотности и фоновый шум, что может создать трудности при выборе параметра eps для DBSCAN

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: что именно делали (scaling, imputation, encoding, PCA – если делали)
  - Масштабирование числовых признаков с использованием StandardScaler
  - Обработка пропусков с помощью SimpleImputer (медиана для числовых, константа для категориальных)
  - Кодирование категориальных признаков с OneHotEncoder (если присутствуют)
- Поиск гиперпараметров:
  - KMeans: диапазон k от 2 до 20, выбор лучшего значения по silhouette score
  - DBSCAN: сетка параметров eps от 0.1 до 1.0 и min_samples от 2 до 8
  - AgglomerativeClustering: диапазон k от 2 до 20 и различные linkage функции (ward, complete, average, single)
  - Выбор лучшего решения основывался на сочетании внутренних метрик качества
- Метрики: silhouette / Davies-Bouldin / Calinski-Harabasz (и как считали для DBSCAN при наличии шума)
  - Для DBSCAN метрики рассчитывались как на всех точках, так и только на нешумовых (с меткой != -1)
- Визуализация: PCA(2D) (и t-SNE, если делали – с какими параметрами)
  - Обязательно использовалась PCA(2D) для визуализации результатов кластеризации
  - Также добавлена визуализация подбора параметров (silhouette vs k и др.)

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):

- KMeans (поиск `k`, фиксировали `random_state`, `n_init`)
  - Диапазон k: от 2 до 20
  - random_state: 42
  - n_init: 10
- Один из:
  - DBSCAN (`eps`, `min_samples`, доля шума)
    - Диапазон eps: от 0.1 до 1.0
    - Диапазон min_samples: от 2 до 8
    - Рассчитывалась доля шумовых точек (с меткой -1)

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: DBSCAN (eps=0.1, min_samples=2)
- Метрики (silhouette / DB / CH): 0.741 / 0.269 / 1467.954
- Если был DBSCAN: доля шума и комментарий: доля шума 0.991 (99.1%), что указывает на то, что почти все точки классифицированы как шум, за исключением малочисленных плотных кластеров
- Коротко: почему это решение выглядит разумным именно для этого датасета
  - DBSCAN оказался лучшим методом для этого датасета, несмотря на высокую долю шума. Это может указывать на сложную структуру данных с множеством выбросов и небольшими плотными кластерами, которые лучше всего выделяются алгоритмом DBSCAN

### 4.2 Dataset B

- Лучший метод и параметры: AgglomerativeClustering (n_clusters=2, linkage=single)
- Метрики (silhouette / DB / CH): 0.521 / 0.342 / 7.184
- Если был DBSCAN: доля шума и комментарий: доля шума 0.000, что означает отсутствие шумовых точек
- Коротко: почему это решение выглядит разумным именно для этого датасета
  - Аггломеративная кластеризация с linkage=single оказалась лучшей для этого датасета, что указывает на наличие структуры данных с цепочечными связями, подходящей для single linkage. Single linkage хорошо справляется с нелинейной структурой и может выделять удлиненные кластеры

### 4.3 Dataset C

- Лучший метод и параметры: DBSCAN (eps=0.1, min_samples=8)
- Метрики (silhouette / DB / CH): 0.500 / 0.716 / 1943.885
- Если был DBSCAN: доля шума и комментарий: доля шума 0.984 (98.4%), что указывает на высокий процент точек, классифицированных как шум
- Коротко: почему это решение выглядит разумным именно для этого датасета
  - DBSCAN снова оказался лучшим методом для этого датасета, хотя и с высокой долей шума. Это говорит о том, что структура данных содержит много разрозненных точек (шум) и несколько плотных кластеров. При min_samples=8 DBSCAN ищет более плотные области, что может соответствовать реальной структуре этого датасета с кластерами разной плотности

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- Где KMeans "ломается" и почему?
  - KMeans продемонстрировал худшие результаты на всех трех датасетах по сравнению с другими методами. В частности, на датасете 1 и 3 он проиграл DBSCAN по метрике silhouette (0.522 против 0.741 и 0.316 против 0.500 соответственно)
  - KMeans плохо работает с нелинейными структурами данных и чувствителен к выбросам
  - Требует компактных, сферических кластеров и одинакового размера
- Где DBSCAN/иерархическая кластеризация выигрывают и почему?
  - DBSCAN оказался лучшим методом для датасетов 1 и 3, особенно на датасете 1, где достиг 0.741 silhouette score при 99.1% шума, что указывает на эффективность в выделении плотных кластеров среди шума
  - Иерархическая кластеризация (AgglomerativeClustering) победила на датасете 2 с linkage=single, что говорит о наличии цепочечной структуры данных, подходящей для single linkage
- Что сильнее всего влияло на результат (масштабирование, выбросы, плотность, пропуски, категориальные признаки)?
  - Масштабирование признаков оказывало критическое влияние на результаты distance-based методов
  - Наличие выбросов и разная плотность кластеров значительно влияли на качество кластеризации
  - Параметры DBSCAN (eps и min_samples) критически важны для достижения хороших результатов, особенно на данных с разной плотностью кластеров

### 5.2 Устойчивость (обязательно для одного датасета)

- Какую проверку устойчивости делали (5 запусков KMeans по разным seed или иной подход)
  - 5 запусков KMeans с разными random_state (0, 42, 84, 126, 168) и расчет среднего ARI между результатами
- Что получилось (в 3-6 строк)
  - Были вычислены метки кластеров для каждого из 5 запусков с оптимальным количеством кластеров
  - Затем рассчитаны ARI (Adjusted Rand Index) между всеми парами результатов
  - Получено среднее значение ARI для оценки устойчивости
  - Результат: средний ARI между запусками составил 1.000, что указывает на полную идентичность результатов
- Вывод: устойчиво/неустойчиво и почему вы так считаете
  - Результаты полностью устойчивы (ARI=1.000), что указывает на высокую стабильность KMeans на данном датасете. Полная идентичность результатов говорит о том, что алгоритм стабильно сходится к одному и тому же решению независимо от начального приближения

### 5.3 Интерпретация кластеров

- Как вы интерпретировали кластеры:
  - Визуализация через PCA(2D) для понимания структуры кластеров
  - Анализ внутренних метрик для оценки качества разбиения
- 3-6 строк выводов
  - Кластеры были интерпретированы через их геометрическое расположение на PCA-визуализации
  - Сравнение метрик позволило оценить компактность и разделенность кластеров
  - Лучший метод определялся по совокупности метрик, а не по одной из них

## 6. Conclusion

4-8 коротких тезисов: чему научились про кластеризацию, метрики и корректный протокол unsupervised-эксперимента.

- KMeans продемонстрировал худшие результаты на всех тестовых датасетах, подтверждая его ограниченность для данных со сложной структурой
- DBSCAN оказался наиболее эффективным для датасетов с шумом и нестандартной формой кластеров, особенно при правильном подборе параметров eps и min_samples
- Внутренние метрики (silhouette, Davies-Bouldin, Calinski-Harabasz) позволяют оценивать качество кластеризации без истинных меток, при этом необходимо использовать их комплексно
- Правильный препроцессинг (масштабирование, обработка пропусков) критически важен для distance-based методов
- Выбор лучшего метода должен основываться на комплексной оценке нескольких метрик, а не на одной
- Аггломеративная кластеризация с разными linkage стратегиями показала свою эффективность для данных с определенной структурой (например, single linkage для цепочечных кластеров)
- Устойчивость результатов кластеризации важна для уверенности в полученных разбиениях, как показал эксперимент с ARI=1.000 для KMeans
- Понимание особенностей данных (распределение признаков, наличие выбросов, форма кластеров) позволяет выбрать наиболее подходящий алгоритм