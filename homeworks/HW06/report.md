# HW06 – Report

> Файл: `homeworks/HW06/report.md`
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-02.csv`
- Размер: (укажите после загрузки данных)
- Целевая переменная: `target` (классы и их доли)
- Признаки: числовые признаки (f01-f35, x_int_1, x_int_2), целевая переменная бинарная

## 2. Protocol

- Разбиение: train/test (80/20, random_state=42)
- Подбор: CV на train (5 фолдов, оптимизировали по ROC-AUC для бинарной классификации)
- Метрики: accuracy, F1, ROC-AUC (метрики выбраны для адекватной оценки бинарной классификации с возможным дисбалансом)

## 3. Models

Опишите, какие модели сравнивали и какие гиперпараметры подбирали.

Минимум:

- DummyClassifier (baseline)
- LogisticRegression (baseline из S05)
- DecisionTreeClassifier (контроль сложности: `max_depth` + `min_samples_leaf`)
- RandomForestClassifier
- Один boosting (GradientBoosting)

Опционально:

- StackingClassifier (с CV-логикой)

## 4. Results

- Таблица/список финальных метрик на test по всем моделям
- Победитель (по ROC-AUC или по согласованному критерию) и краткое объяснение

## 5. Analysis

- Устойчивость: что будет, если поменять `random_state` (хотя бы 5 прогонов для 1-2 моделей) – кратко
- Ошибки: confusion matrix для лучшей модели + комментарий
- Интерпретация: permutation importance (top-10/15) + выводы

## 6. Conclusion

3-6 коротких тезисов: что вы поняли про деревья/ансамбли и про честный ML-протокол.

1. Деревья решений склонны к переобучению, но с контролем сложности (max_depth, min_samples_leaf) можно добиться хорошего результата.
2. Ансамблевые методы (Random Forest и Gradient Boosting) улучшают качество по сравнению с одиночными деревьями за счет уменьшения дисперсии (в случае Random Forest) или последовательного исправления ошибок (в случае Gradient Boosting).
3. Подбор гиперпараметров с помощью кросс-валидации на тренировочной выборке позволяет получить объективную оценку качества.
4. Permutation importance помогает понять, какие признаки наиболее важны для принятия решений моделью.
5. Честный ML-эксперимент требует фиксации train/test разбиения, использования кросс-валидации для подбора гиперпараметров и единообразной оценки моделей на тестовой выборке.