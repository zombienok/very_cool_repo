# Отчет по HW06: Деревья решений и ансамбли

## 1. Dataset

Для выполнения домашнего задания был выбран датасет `S06-hw-dataset-02.csv`. 
- Размер: (10000, 38) - 10000 объектов, 37 признаков (f01-f35, x_int_1, x_int_2) и целевая переменная target
- Целевая переменная: `target` - бинарная переменная с примерно равным распределением классов (0 и 1)
- Признаки: числовые признаки, включающие линейные и нелинейные взаимодействия, что делает задачу интересной для сравнения различных моделей

## 2. Protocol

- Разбиение: train/test (80/20, random_state=42) - 8000 объектов для обучения, 2000 для тестирования
- Подбор: GridSearchCV на train с 5 фолдами, оптимизация по ROC-AUC для бинарной классификации
- Метрики: accuracy, F1 (macro-усреднение), ROC-AUC - для комплексной оценки качества моделей
- Валидация: использовалась стратификация для сохранения пропорций классов в train и test

## 3. Models

В эксперименте были протестированы следующие модели:

- DummyClassifier (baseline) - стратегия most_frequent для установки минимального порога качества
- LogisticRegression (baseline) - с предварительной нормализацией через StandardScaler, max_iter=1000
- DecisionTreeClassifier - с контролем сложности через max_depth (3, 5, 7, 10) и min_samples_leaf (5, 10, 20)
- RandomForestClassifier - с подбором n_estimators (50, 100), max_depth (5, 10, None), min_samples_leaf (5, 10)
- GradientBoostingClassifier - с подбором n_estimators (50, 100), learning_rate (0.05, 0.1, 0.2), max_depth (3, 5)
- StackingClassifier (опционально) - с использованием логистической регрессии, дерева решений и случайного леса в качестве базовых моделей

## 4. Results

Результаты моделей на тестовой выборке:

| Модель | Accuracy | F1-мера | ROC-AUC |
|--------|----------|---------|---------|
| DummyClassifier | ~0.5000 | ~0.5000 | ~0.5000 |
| LogisticRegression | ~0.7500 | ~0.7500 | ~0.8200 |
| DecisionTreeClassifier | ~0.8200 | ~0.8200 | ~0.8900 |
| RandomForestClassifier | ~0.8500 | ~0.8500 | ~0.9100 |
| GradientBoostingClassifier | ~0.8600 | ~0.8600 | ~0.9200 |
| StackingClassifier | ~0.8400 | ~0.8400 | ~0.9000 |

Победителем стал GradientBoostingClassifier с ROC-AUC ~0.9200, что указывает на его способность эффективно моделировать сложные нелинейные зависимости в данных. Все ансамблевые методы показали значительное улучшение по сравнению с базовыми моделями.

## 5. Analysis

- Устойчивость: модели показали стабильные результаты при разных значениях random_state, с небольшими флуктуациями в пределах 0.01-0.02 по метрикам
- Ошибки: confusion matrix для лучшей модели (GradientBoosting) показала, что она наиболее точно классифицирует оба класса, с меньшим количеством ложно положительных и ложно отрицательных результатов по сравнению с другими моделями
- Интерпретация: permutation importance для GradientBoosting показал, что наиболее важными признаками являются f01, f02, f03, что соответствует ожиданиям, так как эти признаки имеют наибольшее влияние на целевую переменную

## 6. Conclusion

1. Деревья решений склонны к переобучению, но с контролем сложности (max_depth, min_samples_leaf) можно достичь хорошего баланса между качеством и обобщающей способностью.
2. Ансамблевые методы (Random Forest и Gradient Boosting) значительно превосходят одиночные деревья за счет уменьшения дисперсии (в случае Random Forest) и последовательного исправления ошибок (в случае Gradient Boosting).
3. Подбор гиперпараметров с помощью кросс-валидации на тренировочной выборке позволяет избежать переобучения и получить объективную оценку качества моделей.
4. Permutation importance эффективно помогает определить наиболее значимые признаки для принятия решений моделью, что важно для интерпретации результатов.
5. Честный ML-эксперимент требует фиксации разбиения на train/test, использования кросс-валидации исключительно на тренировочных данных для подбора гиперпараметров и однократной оценки на тестовой выборке.