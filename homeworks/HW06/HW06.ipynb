{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW06: Деревья решений и ансамбли\n",
    "\n",
    "## Задание\n",
    "\n",
    "Цель: закрепить понимание деревьев решений и ансамблевых методов (bagging, random forest, boosting, stacking), а также провести честный ML-эксперимент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорты\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Фиксируем случайный.seed для воспроизводимости\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.1. Загрузка данных и первичный анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "# Выберите один из датасетов: S06-hw-dataset-01.csv, S06-hw-dataset-02.csv, S06-hw-dataset-03.csv, S06-hw-dataset-04.csv\n",
    "df = pd.read_csv('S06-hw-dataset-02.csv')  # Измените на нужный датасет\n",
    "\n",
    "# Просмотр данных\n",
    "print(\"Форма данных:\", df.shape)\n",
    "print(\"\\nПервые строки:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nИнформация о данных:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nСтатистики:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Распределение таргета\n",
    "print(\"\\nРаспределение таргета:\")\n",
    "print(df['target'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка пропусков и типов столбцов\n",
    "print(\"Пропущенные значения:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nТипы столбцов:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Определение X и y\n",
    "# Предполагаем, что столбец 'id' не используется как признак\n",
    "if 'id' in df.columns:\n",
    "    X = df.drop(['target', 'id'], axis=1)\n",
    "else:\n",
    "    X = df.drop(['target'], axis=1)\n",
    "    \n",
    "y = df['target']\n",
    "\n",
    "print(f\"Форма X: {X.shape}\")\n",
    "print(f\"Форма y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.2. Train/Test-сплит и воспроизводимость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=RANDOM_STATE, \n",
    "    stratify=y  # Для классификации используем стратификацию\n",
    ")\n",
    "\n",
    "print(f\"Размер обучающей выборки: {X_train.shape[0]}\")\n",
    "print(f\"Размер тестовой выборки: {X_test.shape[0]}\")\n",
    "print(f\"Доли классов в train: {y_train.value_counts(normalize=True).to_dict()}\")\n",
    "print(f\"Доли классов в test: {y_test.value_counts(normalize=True).to_dict()}\")\n",
    "\n",
    "# Пояснение важности фиксированного seed и стратификации\n",
    "print(\"\\nФиксированный seed обеспечивает воспроизводимость результатов.\")\n",
    "print(\"Стратификация сохраняет пропорции классов в train и test, что важно для корректной оценки модели.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.3. Baseline'ы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline 1: DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent', random_state=RANDOM_STATE)\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy_clf.predict(X_test)\n",
    "\n",
    "print(\"Baseline 1 - DummyClassifier (most_frequent strategy):\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_dummy):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_dummy, average='macro'):.4f}\")\n",
    "if len(np.unique(y)) == 2:  # Если бинарная классификация\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_test, dummy_clf.predict_proba(X_test)[:, 1]):.4f}\")\n",
    "\n",
    "# Baseline 2: Logistic Regression\n",
    "lr_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lr', LogisticRegression(random_state=RANDOM_STATE, max_iter=1000))\n",
    "])\n",
    "\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "y_pred_lr = lr_pipeline.predict(X_test)\n",
    "\n",
    "print(\"\\nBaseline 2 - Logistic Regression:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_lr, average='macro'):.4f}\")\n",
    "if len(np.unique(y)) == 2:  # Если бинарная классификация\n",
    "    y_pred_proba_lr = lr_pipeline.predict_proba(X_test)[:, 1]\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_lr):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.4. Модели недели 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель 1: Decision Tree с контролем сложности\n",
    "dt_params = {\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'min_samples_leaf': [5, 10, 20]\n",
    "}\n",
    "\n",
    "dt_grid = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    dt_params,\n",
    "    cv=5,\n",
    "    scoring='roc_auc' if len(np.unique(y)) == 2 else 'f1_macro',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "dt_grid.fit(X_train, y_train)\n",
    "best_dt = dt_grid.best_estimator_\n",
    "\n",
    "y_pred_dt = best_dt.predict(X_test)\n",
    "if len(np.unique(y)) == 2:\n",
    "    y_pred_proba_dt = best_dt.predict_proba(X_test)[:, 1]\n",
    "    dt_roc_auc = roc_auc_score(y_test, y_pred_proba_dt)\n",
    "else:\n",
    "    dt_roc_auc = None\n",
    "\n",
    "print(\"Decision Tree (best params):\", dt_grid.best_params_)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_dt):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_dt, average='macro'):.4f}\")\n",
    "if dt_roc_auc is not None:\n",
    "    print(f\"ROC-AUC: {dt_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель 2: Random Forest\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_leaf': [5, 10]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    rf_params,\n",
    "    cv=5,\n",
    "    scoring='roc_auc' if len(np.unique(y)) == 2 else 'f1_macro',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train, y_train)\n",
    "best_rf = rf_grid.best_estimator_\n",
    "\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "if len(np.unique(y)) == 2:\n",
    "    y_pred_proba_rf = best_rf.predict_proba(X_test)[:, 1]\n",
    "    rf_roc_auc = roc_auc_score(y_test, y_pred_proba_rf)\n",
    "else:\n",
    "    rf_roc_auc = None\n",
    "\n",
    "print(\"Random Forest (best params):\", rf_grid.best_params_)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_rf, average='macro'):.4f}\")\n",
    "if rf_roc_auc is not None:\n",
    "    print(f\"ROC-AUC: {rf_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель 3: Boosting (Gradient Boosting)\n",
    "gb_params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "gb_grid = GridSearchCV(\n",
    "    GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    gb_params,\n",
    "    cv=5,\n",
    "    scoring='roc_auc' if len(np.unique(y)) == 2 else 'f1_macro',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gb_grid.fit(X_train, y_train)\n",
    "best_gb = gb_grid.best_estimator_\n",
    "\n",
    "y_pred_gb = best_gb.predict(X_test)\n",
    "if len(np.unique(y)) == 2:\n",
    "    y_pred_proba_gb = best_gb.predict_proba(X_test)[:, 1]\n",
    "    gb_roc_auc = roc_auc_score(y_test, y_pred_proba_gb)\n",
    "else:\n",
    "    gb_roc_auc = None\n",
    "\n",
    "print(\"Gradient Boosting (best params):\", gb_grid.best_params_)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_gb):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_gb, average='macro'):.4f}\")\n",
    "if gb_roc_auc is not None:\n",
    "    print(f\"ROC-AUC: {gb_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель 4: Stacking (опционально)\n",
    "base_models = [\n",
    "    ('dt', DecisionTreeClassifier(max_depth=5, random_state=RANDOM_STATE)),\n",
    "    ('lr', Pipeline([('scaler', StandardScaler()), ('lr', LogisticRegression(random_state=RANDOM_STATE, max_iter=1000))]))\n",
    "]\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=LogisticRegression(random_state=RANDOM_STATE),\n",
    "    cv=5  # Кросс-валидация для получения прогнозов базовых моделей\n",
    ")\n",
    "\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "y_pred_stack = stacking_clf.predict(X_test)\n",
    "\n",
    "if len(np.unique(y)) == 2:\n",
    "    y_pred_proba_stack = stacking_clf.predict_proba(X_test)[:, 1]\n",
    "    stack_roc_auc = roc_auc_score(y_test, y_pred_proba_stack)\n",
    "else:\n",
    "    stack_roc_auc = None\n",
    "\n",
    "print(\"Stacking Classifier:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_stack):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_stack, average='macro'):.4f}\")\n",
    "if stack_roc_auc is not None:\n",
    "    print(f\"ROC-AUC: {stack_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.5. Метрики качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравнение всех моделей по всем метрикам\n",
    "models_results = {}\n",
    "\n",
    "# Словарь моделей\n",
    "all_models = {\n",
    "    'Dummy': (dummy_clf, y_pred_dummy, None if len(np.unique(y)) != 2 else dummy_clf.predict_proba(X_test)[:, 1]),\n",
    "    'Logistic_Regression': (lr_pipeline, y_pred_lr, y_pred_proba_lr if len(np.unique(y)) == 2 else None),\n",
    "    'Decision_Tree': (best_dt, y_pred_dt, y_pred_proba_dt if len(np.unique(y)) == 2 else None),\n",
    "    'Random_Forest': (best_rf, y_pred_rf, y_pred_proba_rf if len(np.unique(y)) == 2 else None),\n",
    "    'Gradient_Boosting': (best_gb, y_pred_gb, y_pred_proba_gb if len(np.unique(y)) == 2 else None),\n",
    "    'Stacking': (stacking_clf, y_pred_stack, y_pred_proba_stack if len(np.unique(y)) == 2 else None)\n",
    "}\n",
    "\n",
    "# Вычисляем метрики для всех моделей\n",
    "for name, (model, y_pred, y_proba) in all_models.items():\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    if y_proba is not None:\n",
    "        roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    else:\n",
    "        roc_auc = None\n",
    "    \n",
    "    models_results[name] = {\n",
    "        'accuracy': acc,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc\n",
    "    }\n",
    "\n",
    "# Вывод таблицы результатов\n",
    "results_df = pd.DataFrame(models_results).T\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Графики\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Confusion Matrix для лучшей модели (предположим, это Random Forest)\n",
    "best_model_name = 'Random_Forest'  # Можно определить программно какую модель выбрать как лучшую\n",
    "best_y_pred = all_models[best_model_name][1]\n",
    "\n",
    "cm = confusion_matrix(y_test, best_y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=axes[0,0])\n",
    "axes[0,0].set_title(f'Confusion Matrix - {best_model_name}')\n",
    "axes[0,0].set_xlabel('Predicted')\n",
    "axes[0,0].set_ylabel('Actual')\n",
    "\n",
    "# ROC Curve для бинарной классификации\n",
    "if len(np.unique(y)) == 2:\n",
    "    from sklearn.metrics import roc_curve\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test, all_models[best_model_name][2])\n",
    "    axes[0,1].plot(fpr, tpr, label=f'{best_model_name} (AUC = {models_results[best_model_name][\"roc_auc\"]:.3f})')\n",
    "    axes[0,1].plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "    axes[0,1].set_xlabel('False Positive Rate')\n",
    "    axes[0,1].set_ylabel('True Positive Rate')\n",
    "    axes[0,1].set_title('ROC Curve')\n",
    "    axes[0,1].legend()\n",
    "else:\n",
    "    axes[0,1].text(0.5, 0.5, 'ROC-AUC не применима\\\\nк мультиклассу', ha='center', va='center', transform=axes[0,1].transAxes)\n",
    "    axes[0,1].set_title('ROC Curve (not applicable for multiclass)')\n",
    "\n",
    "# Сравнение метрик\n",
    "metrics_comparison = results_df[['accuracy', 'f1_score']].dropna(axis=1, how='all')\n",
    "metrics_comparison.plot(kind='bar', ax=axes[1,0])\n",
    "axes[1,0].set_title('Сравнение Accuracy и F1 Score')\n",
    "axes[1,0].set_xlabel('Модель')\n",
    "axes[1,0].set_ylabel('Метрика')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# ROC-AUC если применимо\n",
    "if 'roc_auc' in results_df.columns and not results_df['roc_auc'].isna().all():\n",
    "    results_df['roc_auc'].dropna().plot(kind='bar', ax=axes[1,1])\n",
    "    axes[1,1].set_title('ROC-AUC')\n",
    "    axes[1,1].set_xlabel('Модель')\n",
    "    axes[1,1].set_ylabel('ROC-AUC')\n",
    "    axes[1,1].tick_params(axis='x', rotation=45)\n",
    "else:\n",
    "    axes[1,1].text(0.5, 0.5, 'ROC-AUC не доступна', ha='center', va='center', transform=axes[1,1].transAxes)\n",
    "    axes[1,1].set_title('ROC-AUC')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.6. Интерпретация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем лучшую модель (например, по ROC-AUC для бинарной или F1 для мультикласса)\n",
    "if len(np.unique(y)) == 2:\n",
    "    best_model_key = max(models_results.keys(), key=lambda x: models_results[x]['roc_auc'] if models_results[x]['roc_auc'] is not None else -float('inf'))\n",
    "else:\n",
    "    best_model_key = max(models_results.keys(), key=lambda x: models_results[x]['f1_score'])\n",
    "\n",
    "best_model = all_models[best_model_key][0]\n",
    "print(f\"Лучшая модель: {best_model_key}\")\n",
    "\n",
    "# Permutation Importance\n",
    "perm_importance = permutation_importance(best_model, X_test, y_test, n_repeats=10, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "\n",
    "# Получаем топ-10 признаков\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance_mean': perm_importance.importances_mean,\n",
    "    'importance_std': perm_importance.importances_std\n",
    "}).sort_values(by='importance_mean', ascending=False)\n",
    "\n",
    "top_features = importance_df.head(10)\n",
    "print(\"\\nТоп-10 наиболее важных признаков:\")\n",
    "print(top_features)\n",
    "\n",
    "# Визуализация permutation importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(range(len(top_features)), top_features['importance_mean'], xerr=top_features['importance_std'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Permutation Importance')\n",
    "plt.title(f'Top-10 Feature Importances ({best_model_key})')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/permutation_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Сохранение артефактов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем метрики на тесте\n",
    "with open('artifacts/metrics_test.json', 'w') as f:\n",
    "    json.dump({k: {metric: float(v) if isinstance(v, (np.float64, np.float32)) else v for metric, v in v.items()} for k, v in models_results.items()}, f, indent=2)\n",
    "\n",
    "# Сохраняем результаты подбора гиперпараметров\n",
    "search_summaries = {\n",
    "    'DecisionTree': {\n",
    "        'best_params': dt_grid.best_params_,\n",
    "        'cv_score': float(dt_grid.best_score_),\n",
    "        'model_type': 'DecisionTree'\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'best_params': rf_grid.best_params_,\n",
    "        'cv_score': float(rf_grid.best_score_),\n",
    "        'model_type': 'RandomForest'\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'best_params': gb_grid.best_params_,\n",
    "        'cv_score': float(gb_grid.best_score_),\n",
    "        'model_type': 'GradientBoosting'\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('artifacts/search_summaries.json', 'w') as f:\n",
    "    json.dump(search_summaries, f, indent=2)\n",
    "\n",
    "# Сохраняем лучшую модель\n",
    "joblib.dump(all_models[best_model_key][0], 'artifacts/best_model.joblib')\n",
    "\n",
    "# Сохраняем метаданные лучшей модели\n",
    "best_model_meta = {\n",
    "    'model_name': best_model_key,\n",
    "    'model_type': str(type(all_models[best_model_key][0])),\n",
    "    'test_metrics': {\n",
    "        'accuracy': float(models_results[best_model_key]['accuracy']),\n",
    "        'f1_score': float(models_results[best_model_key]['f1_score']),\n",
    "        'roc_auc': float(models_results[best_model_key]['roc_auc']) if models_results[best_model_key]['roc_auc'] is not None else None\n",
    "    },\n",
    "    'cv_score': getattr(eval(f'{best_model_key.lower()}_grid'), 'best_score_', None),\n",
    "    'best_params': getattr(eval(f'{best_model_key.lower()}_grid'), 'best_params_', None) if best_model_key in ['Decision_Tree', 'Random_Forest', 'Gradient_Boosting'] else 'N/A'\n",
    "}\n",
    "\n",
    "with open('artifacts/best_model_meta.json', 'w') as f:\n",
    "    json.dump(best_model_meta, f, indent=2)\n",
    "\n",
    "print(\"Артефакты сохранены успешно!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}